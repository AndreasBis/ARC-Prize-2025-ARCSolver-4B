{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaL4","dataSources":[{"sourceId":91496,"databundleVersionId":11802066,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":282751,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":239470,"modelId":222398}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --no-index --find-links=/kaggle/input/arc-prize-2025-arcsolver-4b-libraries/wheels vllm numpy scipy torch torchvision transformers","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import vllm\nimport numpy\nimport scipy\nimport torch\nimport transformers\n\nprint(f'vLLM version: {vllm.__version__}')\nprint(f'Numpy version: {numpy.__version__}')\nprint(f'Scipy version: {scipy.__version__}')\nprint(f'PyTorch version: {torch.__version__}')\nprint(f'Transformers version: {transformers.__version__}')","metadata":{"_kg_hide-output":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport sys\nimport json\nimport multiprocessing as mp\n\nSCRIPTS_PATH = '/kaggle/input/arc-prize-2025-arcsolver-4b-scripts/Code'\nsys.path.append(SCRIPTS_PATH)\n\nimport utils\nimport wrapper","metadata":{"_kg_hide-output":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"TEST_CHALLENGES_PATH = '/kaggle/input/arc-prize-2025/arc-agi_test_challenges.json'\nMODEL_PATH = '/kaggle/input/gemma-3/transformers/gemma-3-4b-it/1'\nSUBMISSION_PATH = 'submission.json'\nNUM_EASY_TASKS = 48 if os.getenv('KAGGLE_IS_COMPETITION_RERUN') else 8\nNUM_PROCESSES = 4\nSEED = 42","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\nimport numpy as np\nimport torch\n\ndef set_seed(seed_value):\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    torch.manual_seed(seed_value)\n\nset_seed(SEED)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(TEST_CHALLENGES_PATH, 'r') as f:\n    test_challenges = json.load(f)\n\ntasks_with_scores = []\n\nfor task_id, task_data in test_challenges.items():\n    difficulty_score = utils.calculate_grid_dot_product(task_data['test'][0]['input'])\n    tasks_with_scores.append((difficulty_score, task_id, task_data))\n\ntasks_with_scores.sort()\n\ntasks_to_process = tasks_with_scores[:NUM_EASY_TASKS]\ntasks_to_skip = tasks_with_scores[NUM_EASY_TASKS:]\n\nprint(f'Selected {len(tasks_to_process)} tasks to solve.')\nprint(f'Will generate blank submissions for {len(tasks_to_skip)} tasks.')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if __name__ == '__main__':\n    mp.set_start_method('spawn', force=True)\n\n    manager = mp.Manager()\n    results_dict = manager.dict()\n\n    chunk_size = (len(tasks_to_process) + NUM_PROCESSES - 1) // NUM_PROCESSES\n    task_chunks = [tasks_to_process[i:i + chunk_size] for i in range(0, len(tasks_to_process), chunk_size)]\n    \n    pool_args = [(task_chunks[i], i, results_dict, MODEL_PATH, SEED) for i in range(len(task_chunks))]\n    \n    processes = []\n    for args in pool_args:\n        p = mp.Process(target=wrapper.subprocess_wrapper, args=(args,))\n        processes.append(p)\n        p.start()\n\n    for p in processes:\n        p.join()\n    \n    submission_json = dict(results_dict)\n\n    for _, task_id, task_data in tasks_to_skip:\n        num_test_inputs = len(task_data.get('test', []))\n        blank_predictions = [{'attempt_1': [], 'attempt_2': []} for _ in range(num_test_inputs)]\n        submission_json[task_id] = blank_predictions\n\n    for task_id in test_challenges.keys():\n        if task_id not in submission_json:\n            num_test_inputs = len(test_challenges[task_id].get('test', []))\n            blank_predictions = [{'attempt_1': [], 'attempt_2': []} for _ in range(num_test_inputs)]\n            submission_json[task_id] = blank_predictions\n\n    with open(SUBMISSION_PATH, 'w') as f:\n        json.dump(submission_json, f)\n\n    print(f'Submission file created at: {SUBMISSION_PATH}')\n\n    print('\\n--- Submission Sample ---')\n    for i, (task_id, preds) in enumerate(submission_json.items()):\n        if i >= 3:\n            break\n        print(f'\\'{task_id}\\': {preds}')","metadata":{"_kg_hide-output":true,"trusted":true},"outputs":[],"execution_count":null}]}